# training:
epochs: 1000
batch_size: 128
learning_rate: 0.0001
weight_decay: 0.00001

# data:
dataset: stock
seq_len: 96

# model:
input_channels: 6
diffusion_steps: 200 # DDPM steps
sampling_timesteps: 200
n_layer_enc: 1
n_layer_dec: 2
d_model: 64
n_heads: 4
ema: true
ema_warmup: 100

# logging:
logging_iter: 10

